%
% Copyright Â© 2017 Peeter Joot.  All Rights Reserved.
% Licenced as described in the file LICENSE under the root directory of this GIT repository.
%
\section{What's this course about?}

\begin{itemize}
\item Science of optimization.
\item problem formulation, design, analysis of engineering systems.
\end{itemize}

\section{Basic concepts}

\begin{itemize}
\item Basic concepts.  convex sets, functions, problems.
\item Theory (about 40 \% of the material).  Specifically Lagrangian duality.
\item Algorithms: gradient descent, Newton's, interior point, ...
\end{itemize}

Homework will involve computational work (solving problems, ...)

\section{Goals}

\begin{itemize}
\item Recognize and formulate engineering problems as convex optimization problems.
\item To develop (Matlab) code to solve problems numerically.
\item To characterize the solutions via duality theory
\item NOT a math course, but lots of proofs.
\item NOT a communications course, but lots of ... (?)
\item NOT a CS course, but lots of useful algorithms.
\end{itemize}

\makedefinition{Mathematical program}{dfn:L1introduction:1}{
\begin{equation}\label{eqn:L1introduction:20}
\min_\Bx F_0(\Bx)
\end{equation}
where \( \Bx = (x_1, x_2, \cdots, x_m) \in \Rm{m} \) is subject to constraints \( F_i : \Rm{m} \rightarrow \Rm{1} \)
\begin{equation}\label{eqn:L1introduction:40}
F_i(\Bx) \le 0, \qquad i = 1, \cdots, m.
\end{equation}
The function \( F_0 : \Rm{m} \rightarrow \Rm{1} \) is called the ``objective function''.
} % definition

Solving a problem produces:

An optimal \(\Bx^\conj\) is a value \( \Bx \) that gives the smallest value among all the feasible \( \Bx \) for the objective function \( F_0 \).  Such a function is sketched in \cref{fig:ConvexObjectiveFunction:ConvexObjectiveFunctionFig1}.

\imageFigure{../figures/ece1505-convex-optimization/ConvexObjectiveFunctionFig1}{Convex objective function.}{fig:ConvexObjectiveFunction:ConvexObjectiveFunctionFig1}{0.3}

\begin{itemize}
\item A convex objective looks like a bowl, ``holds water''.
\item If connect two feasible points line segment in the ? above bottom of the bowl.
\end{itemize}

A non-convex function is illustrated in \cref{fig:NonConvexObjectiveFunction:NonConvexObjectiveFunctionFig2}, which has a number of local minimums.

\imageFigure{../figures/ece1505-convex-optimization/NonConvexObjectiveFunctionFig2}{Non-convex (wavy) figure with a number of local minimums.}{fig:NonConvexObjectiveFunction:NonConvexObjectiveFunctionFig2}{0.2}

\section{Example: Line fitting.}

A linear fit of some points distributed around a line \( y = a x + b \) is plotted in \cref{fig:LinearFit:LinearFitFig3}.  Here \( a, b \) are the optimization variables \( \Bx = (a, b) \).

\imageFigure{../figures/ece1505-convex-optimization/LinearFitFig3}{Linear fit of points around a line.}{fig:LinearFit:LinearFitFig3}{0.2}

How is the solution for such a best fit line obtained?

\paragraph{Approach 1:  Calculus minimization of a multivariable error function.}
Describe an error function, describing how far from the line a given point is.
\begin{equation}\label{eqn:L1introduction:100}
y_i - (a x_i + b),
\end{equation}
Because this can be positive or negative, we can define a squared variant of this, and then sum over all data points.
\begin{equation}\label{eqn:L1introduction:120}
F_0 = \sum_{i=1}^n \lr{ y_i - (a x_i + b) }^2.
\end{equation}
One way to solve (for \( a, b \)): Take the derivatives
\begin{equation}\label{eqn:L1introduction:140}
\begin{aligned}
\PD{a}{F_0} &= \sum_{i=1}^n 2 ( y_i - (a x_i + b) )(-x_i) = 0 \\
\PD{b}{F_0} &= \sum_{i=1}^n 2 ( y_i - (a x_i + b) )(-1) = 0.
\end{aligned}
\end{equation}
%
This yields
\begin{equation}\label{eqn:L1introduction:160}
\begin{aligned}
\sum_{i = 1}^n y_i     &= \lr{\sum_{i = 1}^n x_i} a + \lr{\sum_{i = 1}^n 1} b \\
\sum_{i = 1}^n x_i y_i &= \lr{\sum_{i = 1}^n x_i^2} a + \lr{\sum_{i = 1}^n x_i} b.
\end{aligned}
\end{equation}
In matrix form, this is
\begin{equation}\label{eqn:L1introduction:180}
\begin{bmatrix}
\sum x_i y_i \\
\sum y_i
\end{bmatrix}
=
\begin{bmatrix}
\sum x_i^2 & \sum x_i \\
\sum x_i & n
\end{bmatrix}
\begin{bmatrix}
a \\
b
\end{bmatrix}.
\end{equation}
If invertible, have an analytic solution for \( (a^\conj, b^\conj) \).  This is a convex optimization problem because \( F(x) = x^2 \) is a convex ``quadratic program''.  In general a quadratic program has the structure
\begin{equation}\label{eqn:L1introduction:200}
F(a, b) = (\cdots) a^2 + (\cdots) a b + (\cdots) b^2.
\end{equation}
\paragraph{Approach 2:  Linear algebraic formulation.}
\begin{equation}\label{eqn:L1introduction:220}
\begin{bmatrix}
y_1 \\
\vdots \\
y_n
\end{bmatrix}
=
\begin{bmatrix}
x_1 & 1 \\
\vdots & \vdots \\
x_n & 1
\end{bmatrix}
\begin{bmatrix}
a \\
b
\end{bmatrix}
+
\begin{bmatrix}
z_1 \\
\vdots \\
z_n
\end{bmatrix}
,
\end{equation}
or
\begin{equation}\label{eqn:L1introduction:240}
\By = H \Bv + \Bz,
\end{equation}
where \( \Bz \) is the error vector.  The problem is now reduced to : Fit \( \By \) to be as close to \( H \Bv + \Bz \) as possible, or to minimize the norm of the error vector, or
\begin{equation}\label{eqn:L1introduction:260}
\begin{aligned}
\min_\Bv \Norm{ \By - H \Bv }^2_2 &= \min_\Bv \lr{ \By - H \Bv }^\T \lr{ \By - H \Bv } \\
&= \min_\Bv \lr{ \By^\T \By - \By^\T H \Bv - \Bv^\T H \By + \Bv^\T H^\T H \Bv } \\
&= \min_\Bv \lr{ \By^\T \By - 2 \By^\T H \Bv + \Bv^\T H^\T H \Bv }.
\end{aligned}
\end{equation}
%
It is now possible to take the derivative with respect to the \( \Bv \) vector (i.e. the gradient with respect to the coordinates of the constraint vector)
\begin{equation}\label{eqn:L1introduction:280}
\begin{aligned}
\PD{\Bv}{}
\lr{ \By^\T \By - 2 \By^\T H \Bv + \Bv^\T H^\T H \Bv }
&= - 2 \By^\T H + 2 \Bv^\T H^\T H \\
&= 0,
\end{aligned}
\end{equation}
or
\begin{equation}\label{eqn:L1introduction:300}
(H^\T H) \Bv = H^\T \By,
\end{equation}
so, assuming that \( H^\T H \) is invertible, the optimization problem has solution
\begin{equation}\label{eqn:L1introduction:320}
\Bv^\conj = (H^\T H)^{-1} H^\T \By,
\end{equation}
where
\begin{equation}\label{eqn:L1introduction:340}
\begin{aligned}
H^\T H
&=
\begin{bmatrix}
x_1 & \cdots & x_n \\
 1  & \cdots & 1   \\
\end{bmatrix}
\begin{bmatrix}
x_1 & 1 \\
\vdots & \vdots \\
x_n & 1
\end{bmatrix} \\
&=
\begin{bmatrix}
\sum x_i^2 & \sum x_i \\
\sum x_i & n
\end{bmatrix}
,
\end{aligned}
\end{equation}
as seen in the calculus approach.
\section{Maximum Likelyhood Estimation (MLE).}
It is reasonable to ask why the 2-norm was picked for the objective function?
\begin{itemize}
\item One justification is practical: Because we can solve the derivative equation.
\item Another justification: In statistics the error vector \( \Bz = \By - H \Bv \) can be modeled as an IID (Independently and Identically Distributed) Gaussian random variable (i.e. noise).  Under this model, the use of the 2-norm can be viewed as a consequence of such an ML estimation problem (see \citep{boyd2004convex} ch. 7).
\end{itemize}

A Gaussian \cref{fig:Gaussian:GaussianFig4} IID model is given by
\begin{subequations}
\label{eqn:L1introduction:800}
\begin{equation}\label{eqn:L1introduction:360}
y_i = a x_i + b
\end{equation}
\begin{equation}\label{eqn:L1introduction:380}
z_i = y_i - a x_i -b \sim N(O, O^2)
\end{equation}
\begin{equation}\label{eqn:L1introduction:400}
P_Z(z) = \inv{\sqrt{2 \pi \sigma}} \exp\lr{ -\inv{2} z^2/\sigma^2 }.
\end{equation}
\end{subequations}
\imageFigure{../figures/ece1505-convex-optimization/GaussianFig4}{Gaussian probability distribution.}{fig:Gaussian:GaussianFig4}{0.2}
\paragraph{MLE: Maximum Likelyhood Estimator}
Pick \( (a,b) \) to maximize the probability of observed data.
\begin{equation}\label{eqn:L1introduction:420}
\begin{aligned}
(a^\conj, b^\conj)
&= \arg \max P( x, y ; a, b ) \\
&= \arg \max P_Z( y - (a x + b) ) \\
&= \arg \max \prod_{i = 1}^n \\
&= \arg \max \inv{\sqrt{2 \pi \sigma}} \exp\lr{ -\inv{2} (y_i - a x_i - b)^2/\sigma^2 }.
\end{aligned}
\end{equation}
%
Taking logs gives
\begin{equation}\label{eqn:L1introduction:440}
\begin{aligned}
(a^\conj, b^\conj)
&= \arg \max
\lr{
\textrm{constant}
   -\inv{2} \sum_i (y_i - a x_i - b)^2/\sigma^2
} \\
&= \arg \min \inv{2} \sum_i (y_i - a x_i - b)^2/\sigma^2 \\
&= \arg \min \sum_i (y_i - a x_i - b)^2/\sigma^2
\end{aligned}
\end{equation}
%
Here \( \arg \max \) is not the maximum of the function, but the value of the parameter (the argument) that maximizes the function.
\paragraph{Double sides exponential noise}
A double sided exponential distribution is plotted in \cref{fig:DoubleSidedExponentialDist:DoubleSidedExponentialDistFig5}, and has the mathematical form
%
\begin{equation}\label{eqn:L1introduction:460}
P_Z(z) = \inv{2 c} \exp\lr{ -\inv{c} \Abs{z} }.
\end{equation}
\imageFigure{../figures/ece1505-convex-optimization/DoubleSidedExponentialDistFig5}{Double sided exponential probability distribution.}{fig:DoubleSidedExponentialDist:DoubleSidedExponentialDistFig5}{0.2}

The optimization problem is
\begin{equation}\label{eqn:L1introduction:480}
\begin{aligned}
\max_{a,b} \prod_{i = 1}^n P_z(z_i)
&= \max_{a,b} \prod_{i = 1}^n \inv{2 c} \exp\lr{ -\inv{c} \Abs{z_i} } \\
&= \max_{a,b} \prod_{i = 1}^n \inv{2 c} \exp\lr{ -\inv{c} \Abs{y_i - a x_i - b} } \\
&= \max_{a,b} \lr{\inv{2 c}}^n \exp\lr{ -\inv{c} \sum_{i=1}^n \Abs{y_i - a x_i - b} }.
\end{aligned}
\end{equation}
%
This is a L1 norm problem
\begin{equation}\label{eqn:L1introduction:500}
\min_{a,b} \sum_{i = 1}^n \Abs{ y_i - a x_i - b }.
\end{equation}
%
i.e.
%
\begin{equation}\label{eqn:L1introduction:520}
\min_\Bv \Norm{ \By - H \Bv }_1.
\end{equation}
%
This is still convex, but has no analytic solution, and is an example of a linear program.
\subsection{Solution of linear program}
Introduce helper variables \( t_1, \cdots, t_n \), and
minimize \( \sum_i t_i \), such that
\begin{equation}\label{eqn:L1introduction:540}
\Abs{ y_i - a x_i - b } \le t_i.
\end{equation}
This is now an optimization problem for \( a, b, t_1, \cdots t_n \).  A linear program is defined as
\begin{equation}\label{eqn:L1introduction:560}
\min_{a, b, t_1, \cdots t_n} \sum_i t_i
\end{equation}
such that
\begin{equation}\label{eqn:L1introduction:580}
\begin{aligned}
y_i - a x_i - b \le t_i
y_i - a x_i - b \ge -t_i
\end{aligned}
\end{equation}
\paragraph{Single sided exponential}
What if your noise doesn't look double sided, with only noise for values \( x > 0 \).  Can define a single sided probability distribution, as that of \cref{fig:SingleSidedExponentialDist:SingleSidedExponentialDistFig6}.
\imageFigure{../figures/ece1505-convex-optimization/SingleSidedExponentialDistFig6}{Single sided exponential distribution.}{fig:SingleSidedExponentialDist:SingleSidedExponentialDistFig6}{0.2}
%
\begin{equation}\label{eqn:L1introduction:600}
P_Z(z) =
\left\{
\begin{array}{l l}
\inv{c} e^{-z/c} & \quad \mbox{\( z \ge 0 \)} \\
0 & \quad \mbox{\( z < 0 \)}
\end{array}
\right.
\end{equation}
%
i.e. all \( z_i \) error values are always non-negative.
%
\begin{equation}\label{eqn:L1introduction:620}
\log P_z(z) =
\left\{
\begin{array}{l l}
\textrm{const} - z/c & \quad \mbox{\( z > 0\)} \\
-\infty & \quad \mbox{\( z< 0\)}
\end{array}
\right.
\end{equation}
%
Problem becomes
\begin{equation}\label{eqn:L1introduction:640}
\min_{a, b} \sum_i \lr{ y_i - a x_i - b },
\end{equation}
such that
\begin{equation}\label{eqn:L1introduction:660}
y_i - a x_i - b \ge t_i \qquad \forall i
\end{equation}
\paragraph{Uniform noise}
For noise that is uniformly distributed in a range, as that of \cref{fig:stepProbabilityDist:stepProbabilityDistFig7}, which is constant in the range \( [-c,c] \) and zero outside that range.
\imageFigure{../figures/ece1505-convex-optimization/stepProbabilityDistFig7}{Uniform probability distribution.}{fig:stepProbabilityDist:stepProbabilityDistFig7}{0.2}
\begin{equation}\label{eqn:L1introduction:680}
P_Z(z) =
\left\{
\begin{array}{l l}
\inv{2 c} & \quad \mbox{\( \Abs{z} \le c\)} \\
0 & \quad \mbox{\( \Abs{z} > c. \)}
\end{array}
\right.
\end{equation}
or
\begin{equation}\label{eqn:L1introduction:700}
\log P_Z(z) =
\left\{
\begin{array}{l l}
\textrm{const} & \quad \mbox{\( \Abs{z} \le c\)} \\
-\infty & \quad \mbox{\( \Abs{z} > c. \)}
\end{array}
\right.
\end{equation}
%
MLE solution
\begin{equation}\label{eqn:L1introduction:720}
\max_{a,b} \prod_{i = 1}^n P(x, y; a, b)
=
\max_{a,b} \sum_{i = 1}^n \log P_Z( y_i - a x_i - b ).
\end{equation}
%
Here the argument is constant if \( -c \le y_i - a x_i - b \le c \), so an ML solution is \underline{any} \( (a,b) \) such that
\begin{equation}\label{eqn:L1introduction:740}
\Abs{ y_i - a x_i - b } \le c \qquad \forall i \in 1, \cdots, n.
\end{equation}
%
This is a linear program known as a ``feasibility problem''.
\begin{equation}\label{eqn:L1introduction:760}
\min d
\end{equation}
such that
\begin{equation}\label{eqn:L1introduction:780}
\begin{aligned}
y_i - a x_i - b &\le d \\
y_i - a x_i - b &\ge -d
\end{aligned}
\end{equation}
%
If \( d^\conj \le c \), then the problem is feasible, however, if \( d^\conj > c \) it is infeasible.
\subsection{Method comparison}
The double sided exponential, single sided exponential and uniform probability distributions of \cref{fig:threeDistributions} each respectively represent the point plots of the form \cref{fig:threeDistributionsSamples}.  The double sided exponential samples are distributed on both sides of the line, the single sided strictly above or on the line, and the uniform representing error bars distributed around the line of best fit.

\imageThreeFiguresOneLine
{../figures/ece1505-convex-optimization/DoubleSidedExponentialDistFig5}
{../figures/ece1505-convex-optimization/SingleSidedExponentialDistFig6}
{../figures/ece1505-convex-optimization/stepProbabilityDistFig7}
{Distributions}{fig:threeDistributions}{scale=0.3}

\imageThreeFiguresOneLine
{../figures/ece1505-convex-optimization/LinearFitFig3}
{../figures/ece1505-convex-optimization/LinearFitGtFig3}
{../figures/ece1505-convex-optimization/LinearFitErrorBarFig3}
{Samples}{fig:threeDistributionsSamples}{scale=0.3}
