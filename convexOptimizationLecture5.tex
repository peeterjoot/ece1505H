%
% Copyright © 2017 Peeter Joot.  All Rights Reserved.
% Licenced as described in the file LICENSE under the root directory of this GIT repository.
%
\input{../latex/blogpost.tex}
\renewcommand{\basename}{convexOptimization5}
\renewcommand{\dirname}{notes/ece1505/}
\newcommand{\keywords}{ECE1505H}
\input{../latex/peeter_prologue_print2.tex}

\usepackage{ece1505}
\usepackage{peeters_braket}
\usepackage{peeters_layout_exercise}
\usepackage{peeters_figures}
\usepackage{mathtools}
\usepackage{siunitx}
\usepackage{macros_cal}
\usepackage{enumerate}

\beginArtNoToc
\generatetitle{ECE1505H Convex Optimization.  Lecture 5: XXX.  Taught by Prof.\ Stark Draper}
%\chapter{XXX}
\label{chap:convexOptimization5}

\paragraph{Disclaimer}

Peeter's lecture notes from class.  These may be incoherent and rough.

These are notes for the UofT course ECE1505H, Convex Optimization, taught by Prof. Stark Draper, from \citep{boyd2004convex}.

\paragraph{Last time}

\begin{itemize}
\item examples of sets: planes, half spaces, balls, ellipses, cone of positive semi-definite matrixes
\item generalized inequalities
\item examples of convexity preserving operations
\end{itemize}

\paragraph{Today}

\begin{itemize}
\item more examples of convexity preserving operations
\item separating and supporting hyperplanes
\item basic definitions of convex functions
\item epigraphs, quasi-convexity, sublevel sets
\item first and second order conditions for convexity of differentiable functions.
\end{itemize}

\paragraph{Clarification}

\begin{equation}\label{eqn:convexOptimizationLecture5:20}
x \le_K y \if y - x \in K
\end{equation}

F1

\paragraph{Operations that preserve convexity}

If \( S_\alpha \) is convex \( \forall \alpha \in A \), then

\begin{dmath}\label{eqn:convexOptimizationLecture5:40}
\cup_{\alpha \in A} S_\alpha,
\end{dmath}

is convex.

Example:

\begin{equation}\label{eqn:convexOptimizationLecture5:60}
F(\Bx) = A \Bx + \Bb
\end{equation}

\begin{equation}\label{eqn:convexOptimizationLecture5:80}
\begin{aligned}
\Bx &\in \bbR^n \\
A &\in \bbR^{m \times n} \\
F &: \bbR^{n} \rightarrow \bbR^m \\
\Bb &\in \bbR^m
\end{aligned}
\end{equation}


\begin{enumerate}[(i)]
\item
If \( S \in \bbR^n \) is convex, then

\begin{equation}\label{eqn:convexOptimizationLecture5:100}
F(S) = \setlr{ F(x) | x \in S }
\end{equation}

is convex if \( F \) is affine.
\item

If \( S \in \bbR^m \) is convex, then

\begin{equation}\label{eqn:convexOptimizationLecture5:120}
F^{-1}(S) = \setlr{ x | F(x) \in S }
\end{equation}

is convex.
\end{enumerate}

Example:

\begin{equation}\label{eqn:convexOptimizationLecture5:140}
\setlr{ y | y = A x + b, \Norm{x} \le 1}
\end{equation}

is convex.  Here \( A x + b \) is an affine function (\(F(x)\).  This is the image of a (convex) unit ball, through an affine map.

Earlier saw when defining ellipses

\begin{equation}\label{eqn:convexOptimizationLecture5:160}
y = P^{1/2} x + x_c
\end{equation}

Example :

\begin{equation}\label{eqn:convexOptimizationLecture5:180}
\setlr{ x | \Norm{ A x + b } \le 1 },
\end{equation}

is convex.  This can be seen by writing

\begin{equation}\label{eqn:convexOptimizationLecture5:200}
\setlr{ x | \Norm{ A x + b } \le 1 }
=
\setlr{ x | \Norm{ F(x) } \le 1 }
=
\setlr{ x | F(x) \in \calB  },
\end{equation}

where \( \calB = \setlr{ y | \Norm{y} \le 1 } \).  This is the pre-image (under \(F()\)) of a unit norm ball.

Example:

\begin{equation}\label{eqn:convexOptimizationLecture5:220}
\setlr{ x \in \bbR^n | x_1 A_1 + x_2 A_2 + \cdots x_n A_n \le \calB }
\end{equation}

where \( A_i \in S^m \) and \( \calB \in S^m \), and the inequality is a matrix inequality.  This is a convex set.  The constraint is a ``linear matrix inequality'' (LMI).

This has to do with an affine map:

\begin{equation}\label{eqn:convexOptimizationLecture5:240}
F(x) = B - 1 x_1 A_1 - x_2 A_2 - \cdots x_n A_n \ge 0
\end{equation}

(positive semi-definite inequality).  This is a mapping

\begin{equation}\label{eqn:convexOptimizationLecture5:480}
F : \bbR^n \rightarrow S^m,
\end{equation}

since all \( A_i \) and \( B \) are in \( S^m \).

This \( F(x) = B - A(x) \) is a constant and a factor linear in x, so is affine.  Can be written

\begin{equation}\label{eqn:convexOptimizationLecture5:260}
\setlr{ x | B - A(x) \ge 0 }
=
\setlr{ x | B - A(x) \in S^m_{+} }
\end{equation}

This is a pre-image of a cone of PSD matrices, which is convex.  Therefore, this is a convex set.

\paragraph{Separating hyperplanes}

\maketheorem{Separating hyperplanes}{thm:convexOptimizationLecture5:280}{

If \( S, T \subseteq \bbR^n \) are convex and disjoint
i.e. \( S \cup T = 0\), then
there exists on \( a \in \bbR^n \) \( a \ne 0 \) and a \( b \in \bbR^n \) such that

\begin{equation*}
a^\T x \ge b \, \forall x \in S
\end{equation*}

and
\begin{equation*}
a^\T x < b \,\forall x \in T.
\end{equation*}
} % theorem

F2

Proof in the book.

\maketheorem{Supporting hyperplane}{thm:convexOptimizationLecture5:300}{
If \( S \) is convex then \( \forall x_0 \in \partial S = \closure(S) \ \interior(S) \), where
\( \partial S \) is the boundary of \( S \), then \( \exists \) an \( a \ne 0 \in \bbR^n \) such that \( \Ba^\T x \le \Ba^\T x_0 \, \forall x \in S \).

} % theorem

Here \( \ \) denotes ``without''.

F3

In this example

\begin{itemize}
\item vector \( \Ba \) perpenticular to tangent plane.
\item inner product \( a^\T (x - x_0) \le 0 \).
\end{itemize}

F4

F4b shows that there is not neccessarily a unique supporting hyperplane at any given point, even if \( S \) is convex.

\paragraph{basic definitions of convex functions}

\maketheorem{Convex functions}{thm:convexOptimizationLecture5:320}{
If \( F : \bbR^n \rightarrow \bbR \) is defined on a convex domain (i.e. \( \dom F \subseteq \bbR^n \) is a convex set), then \( F \) is convex if \( \forall x, y \in \dom F \), \( \forall \theta \in [0,1] \in \bbR \)

\begin{equation}\label{eqn:convexOptimizationLecture5:340}
F( \theta x + (1-\theta) y \le \theta F(x) + (1-theta) F(y)
\end{equation}
} % theorem

F5.

Remarks

\begin{itemize}
\item Require \( \dom F \) to be a convex set.  This is required so that the function at the point \( \theta u + (1-\theta) v \) can be evaluated.  i.e. so that \( F(\theta u + (1-\theta) v) \) is well defined.  Example: \( \dom F = (-\infty, 0] \cup [1, \infty) \) is not okay, because a linear combination in \( (0,1) \) would be undesirable.
\item Parameter \( \theta \) is ``how much up'' the line segment connecting \( (u, F(u) \) and \( (v, F(v) \).  This line segment never below the bottom of the bowl.
The function is \underlineAndIndex{concave}, if \( -F \) is convex.
i.e. If the convex function is flipped upside down.  That is

\begin{equation}\label{eqn:convexOptimizationLecture5:360}
F(\theta x + (1-\theta) y ) \ge \theta F(x) + (1-theta) F(y) \,\forall x,y \in \dom F, \theta \in [0,1].
\end{equation}
\item a ``strictly'' convex function means \(\forall \theta \in [0,1] \)

\begin{equation}\label{eqn:convexOptimizationLecture5:380}
F(\theta x + (1-\theta) y ) < \theta F(x) + (1-theta) F(y).
\end{equation}
\item Strictly concave function \( F \) means \( -F \) is strictly convex.
\item Examples:

F6a: not convex or concave.
F6b: not strictly convex (understand).
\end{itemize}

\makedefinition{Epigraph of a function}{dfn:convexOptimizationLecture5:400}{

The epigraph \( \epigraph F \) of a function \( F : \bbR^n \rightarrow \bbR \) is

\begin{equation*}
\epigraph F = \setlr{ (x,t) \in \bbR^{n +1} | x \in \dom F, t \ge F(x) },
\end{equation*}

where \( x \in \bbR^n, t \in \bbR \).
} % definition

F7

\maketheorem{Convexity and epigraph.}{thm:convexOptimizationLecture5:420}{
If \( F \) is convex implies \( \epigraph F \) is a convex set.
} % theorem

Proof:

For convex function, a line segment connecting any 2 points on function is above the function.  i.e. it is \( \epigraph F \).

Many authors will go the other way around, showing \cref{dfn:convexOptimizationLecture5:400} from \cref{thm:convexOptimizationLecture5:420}.  That is:

Pick any 2 points in \( \epigraph F \), \( (x,\mu) \in \epigraph F\) and \( (y, \nu) \in \epigraph F \).  Consider convex combination

\begin{equation}\label{eqn:convexOptimizationLecture5:420}
\theta( x, \mu ) + (1-\theta) (y, \nu) =
(\theta x  (1-\theta) y, \theta \mu  (1-\theta) \nu )
\in \epigraph F,
\end{equation}

since \( \epigraph F \) is a convex set.

By definition of \( \epigraph F \)

\begin{equation}\label{eqn:convexOptimizationLecture5:440}
F( \theta x  (1-\theta) y ) \le \theta \mu  (1-\theta) \nu.
\end{equation}

Picking \( \mu = F(x), \nu = F(y) \) gives
\begin{equation}\label{eqn:convexOptimizationLecture5:460}
F( \theta x  (1-\theta) y ) \le \theta F(x)  (1-\theta) F(y).
\end{equation}

\paragraph{Extended value function}

Sometimes convient to work with ``extended value function''

\begin{dmath}\label{eqn:convexOptimizationLecture5:500}
\tilde{F}(x) =
\left\{
\begin{array}{l l}
F(x) & \quad \mbox{If \( x \in \dom F\)} \\
\infty & \quad \mbox{otherwise.}
\end{array}
\right.
\end{dmath}

Examples:

\begin{itemize}
\item Linear and affine both convex and concave.  F8
\item \( x^2 \) is convex F9
\item \( \log x, \dom F = \bbR_{+} \) concave.  F10
\item \( \Norm{x} \) is convex.  \( \Norm{ \theta x + (1-\theta) y } \le \theta \Norm{ x } + (1-\theta) \Norm{y }
\item \( 1/x \) is convex on \( \setlr{ x | x > 0 } = \dom F \), and concave on \( \setlr{ x | x < 0 } = \dom F \).

\begin{equation}\label{eqn:convexOptimizationLecture5:520}
\tilde{F}(x) =
\left\{
\begin{array}{l l}
\inv{x} & \quad \mbox{If \( x > 0 \)} \\
\infty & \quad \mbox{else.}
\end{array}
\right.
\end{equation}
\end{itemize}

\makedefinition{Sublevel}{dfn:convexOptimizationLecture5:540}{

The sublevel set of a function \( F : \bbR^n \rightarrow \bbR \) is

\begin{equation*}
C(\alpha) = \setlr{ x \in \dom F | F(x) \le \alpha }
\end{equation*}
} % definition

F11

\maketheorem{}{thm:convexOptimizationLecture5:560}{
If \( F \) is convex then \( C(\alpha) \) is a convex set \( \forall \alpha \).
} % theorem

This is not an if and only if condition, as illustrated in

F12

There \( C(\alpha) \) is convex, but the function itself is not.

Proof:

Since \( F \) is convex, then \( \epi F \) is a convex set.

\begin{itemize}
\item
Let

\begin{dmath}\label{eqn:convexOptimizationLecture5:580}
\calA = \setlr{ (x,t) | t = \alpha }
\end{dmath}

is a convex set.

\item
\( \calA \intersection \epi F \)

is a convex set since it is the intersection of convex sets.

\item Project \( \calA \intersection \epi F \) onto \R{n} (i.e. domain of \( F \) ).  The projection is an affine mapping.  Image of a convex set through affine mapping is a convex set.
\end{itemize}

\makedefinition{Quasi-convex.}{dfn:convexOptimizationLecture5:600}{

A function is quasi-convex if \underline{all} of its sublevle sets are convex.
} % definition

\paragraph{composing convex functions}

Properties of convex functions:

\begin{itemize}
\item If \( F \) is convex, then \( \alpha F \) is convex \( \forall \alpha > 0 \).
\item If \( F_1, F_2 \) are convex, then the sum \( F_1 + F_2 \) is convex.
\item If \( F \) is convex, then \( g(x) = F(A x + b) \) is convex \( \forall x \in \setlr{ x | A x + b \in \dom F } \).
\end{itemize}

Note: for the last

\begin{equation}\label{eqn:convexOptimizationLecture5:620}
\begin{aligned}
g &: \bbR^m \rightarrow \bbR  \\
F &: \bbR^n \rightarrow \bbR  \\
x &\in \bbR^m \\
A &\in \bbR^{n \times m} \\
b &\in \bbR^n
\end{aligned}
\end{equation}

Proof (of last):

\begin{dmath}\label{eqn:convexOptimizationLecture5:640}
g( \theta x + (1-\theta) y )
=
F( \theta (A x + b) + (1-\theta) (A y + b) )
\le
\theta F( A x + b) + (1-\theta) F (A y + b)
= \theta g(x) + (1-\theta) g(y).
\end{dmath}
\begin{dmath}\label{eqn:convexOptimizationLecture5:n}
\end{dmath}

\EndArticle
%\EndNoBibArticle
