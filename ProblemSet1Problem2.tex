%
% Copyright © 2017 Peeter Joot.  All Rights Reserved.
% Licenced as described in the file LICENSE under the root directory of this GIT repository.
%
\makeproblem{Inversion formula for ``small'' matrices}{convex-optimization:problemSet1:2}{
Prove the relation

\begin{dmath}\label{eqn:ProblemSet1Problem2:20}
(I + A)^{-1} = I - A,
\end{dmath}

for \(A\) ``small''.  We used this in class to derive the second order expansion of

\begin{dmath}\label{eqn:ProblemSet1Problem2:40}
\log \det(I + A).
\end{dmath}

Prove this result in two ways:
\makesubproblem{}{convex-optimization:problemSet1:2a}
First, prove this for the special case of \( A \in S^n_{++} \) where the eigenvalues are small.
This is what we needed in class. Use a decomposition of \( A \) and Taylor approximation of the eigenvalues.

\makesubproblem{}{convex-optimization:problemSet1:2b}
Next prove the general relation: If \( A \in \Rm{n \times n} \) and \( \Norm{A}_p < 1 \) then \( I - A \) is nonsingular, and

\begin{dmath}\label{eqn:ProblemSet1Problem2:60}
\lr{ I - A }^{-1} = \sum_{k=0}^\infty A^k
\end{dmath}

where

\begin{dmath}\label{eqn:ProblemSet1Problem2:80}
\Norm{(I - A)^{-1}}_p \le \inv{1 - \Norm{A}_p}.
\end{dmath}

The pth matrix norm \( \Norm{A}_p \) is defined in terms of the vector p-norm as

\begin{dmath}\label{eqn:ProblemSet1Problem2:100}
\Norm{A}_p = \sup_{\Bx \ne 0} \frac{\Norm{A \Bx }_p}{\Norm{\Bx}_p}
\end{dmath}

which, using the scaling property of a norm, can be seen to be equivalent to

\begin{dmath}\label{eqn:ProblemSet1Problem2:120}
\Norm{A}_p = \max_{\Norm{\Bx}_p = 1} \Norm{A \Bx}_p.
\end{dmath}

In our derivation in class we used only the zeroth and first-order terms of the expansion.

Some hints that outline one approach to the above result:

\begin{enumerate}[(i)]
\item
One approach to proving the first statement (about non-singularity) is by contradiction: note
that if \( I - A \) is singular then there exists a vector \( \Bv \) such that \((I - A) \Bv = 0 \) and work from
there.
\item Next, consider the telescoping sum

\begin{dmath}\label{eqn:ProblemSet1Problem2:140}
\sum_{k=0}^N A^k (I - A) = I - A^{N+1},
\end{dmath}

and show
\begin{dmath}\label{eqn:ProblemSet1Problem2:160}
\lim_{k \rightarrow \infty } A^k = 0.
\end{dmath}

\item
To show that \( \lim_{k \rightarrow \infty } A^k = 0\), it is helpful first to prove that

\begin{dmath}\label{eqn:ProblemSet1Problem2:180}
\Norm{ A^{k+1} }_p \le \Norm{ A }_p \norm{ A^k }_p.
\end{dmath}

\item
Finally, combine your above results and the properties of a norm to show the desired result.
\end{enumerate}
} % makeproblem

\makeanswer{convex-optimization:problemSet1:2}{
\makeSubAnswer{}{convex-optimization:problemSet1:2a}

TODO.
\makeSubAnswer{}{convex-optimization:problemSet1:2b}

TODO.
}
